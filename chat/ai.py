import torch
from llama_cpp import Llama
import logging
try:
    from .config import MODEL_PATH, AI_SETTINGS, get_system_prompt
except ImportError:
    from chat.config import MODEL_PATH, AI_SETTINGS, get_system_prompt

class AIModel:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.is_loaded = False
        self.model_name = MODEL_PATH
        
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä"""
        try:
            self.logger.info("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞")
            
            # –ü—É—Ç—å –∫ –≤–∞—à–µ–º—É Q2_K —Ñ–∞–π–ª—É
            import os
            model_path = os.path.join(os.path.dirname(__file__), "model", "Roleplay-Llama-3-8B-Q5_K_M.gguf")
            
            if not os.path.exists(model_path):
                self.logger.error(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
                return False
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º: CPU –∏–ª–∏ GPU (–µ—Å–ª–∏ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞)
            gpu_layers = 0
            if torch.cuda.is_available():
                # –°—Ç–∞—Ä—Ç–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤—ã–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ —Å–ª–æ–∏ –Ω–∞ GPU
                # llama.cpp —Å–∞–º –æ–≥—Ä–∞–Ω–∏—á–∏—Ç –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º
                gpu_layers = 100
                try:
                    gpu_name = torch.cuda.get_device_name(0)
                except Exception:
                    gpu_name = "Unknown GPU"
                self.logger.info(f"‚öôÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω GPU: {gpu_name}. –í–∫–ª—é—á–∞—é –æ—Ñ—Ñ–ª–æ–∞–¥ —Å–ª–æ—ë–≤ (n_gpu_layers={gpu_layers}).")
            else:
                self.logger.info("‚öôÔ∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ó–∞–ø—É—Å–∫–∞—é –º–æ–¥–µ–ª—å –Ω–∞ CPU.")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º GGUF –º–æ–¥–µ–ª—å (GPU, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
            self.model = Llama(
                model_path=model_path,
                n_ctx=4096,  # Llama 3 RP –æ–±—ã—á–Ω–æ –≤—ã–≥–æ–¥–Ω–æ –¥–∞—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                n_threads=0,
                verbose=False,
                use_mmap=True,
                use_mlock=False,
                n_gpu_layers=gpu_layers,
                chat_format="llama-3",  # RP-–±–∏–ª–¥ –ø–æ–¥ Llama 3
            )
            
            self.is_loaded = True
            if gpu_layers > 0:
                self.logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å –æ—Ñ—Ñ–ª–æ–∞–¥–æ–º –Ω–∞ GPU")
            else:
                self.logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def _translate_to_russian(self, response: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, —Å–æ—Ö—Ä–∞–Ω—è—è –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        if not response or not response.strip():
            return response
            
        try:
            import re
            from deep_translator import GoogleTranslator
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ
            english_pattern = r'\b[a-zA-Z]{2,}\b'  # –ú–∏–Ω–∏–º—É–º 2 –±—É–∫–≤—ã, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å —Å–æ—é–∑—ã
            english_words = re.findall(english_pattern, response)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ - –ø–µ—Ä–µ–≤–æ–¥–∏–º
            if english_words:
                translator = GoogleTranslator(source='auto', target='ru')
                
                # –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏: —Ä—É—Å—Å–∫–∏–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ
                parts = re.split(r'(\b[a-zA-Z\s]+\b)', response)
                translated_parts = []
                
                for part in parts:
                    if not part.strip():
                        translated_parts.append(part)
                        continue
                        
                    # –ï—Å–ª–∏ —á–∞—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –±—É–∫–≤—ã - –ø–µ—Ä–µ–≤–æ–¥–∏–º
                    if re.search(r'[a-zA-Z]', part):
                        try:
                            translated = translator.translate(part.strip())
                            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–π —á–∞—Å—Ç—å—é, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                            if translated_parts and not translated_parts[-1].endswith(' '):
                                translated_parts.append(' ')
                            translated_parts.append(translated)
                        except Exception:
                            translated_parts.append(part)
                    else:
                        translated_parts.append(part)
                
                result = ''.join(translated_parts)
                # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
                result = re.sub(r'\s+', ' ', result).strip()
                return result
            
            return response  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª, –µ—Å–ª–∏ –Ω–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤
                    
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
            return response
    
    def _finalize_response(self, text: str) -> str:
        """–ü—Ä–∏–≤–æ–¥–∏—Ç –æ—Ç–≤–µ—Ç –∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–º—É –≤–∏–¥—É: —É–±–∏—Ä–∞–µ—Ç –æ–±—Ä—ã–≤—ã, –∑–∞–≤–µ—Ä—à–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º."""
        if not text:
            return text

        import re
        
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ—Ü–∏–∏ –≤ –∑–≤–µ–∑–¥–æ—á–∫–∞—Ö (*—Ç–µ–∫—Å—Ç*)
        text = re.sub(r'\*[^*]+\*', '', text)
        
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ—Ü–∏–∏ –≤ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è—Ö (_—Ç–µ–∫—Å—Ç_)
        text = re.sub(r'_[^_]+_', '', text)
        
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ—Ü–∏–∏ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö [—Ç–µ–∫—Å—Ç]
        text = re.sub(r'\[[^\]]+\]', '', text)
        
        # –£–õ–£–ß–®–ï–ù–ò–ï: –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–º–µ—à–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–º–µ—à–∞–Ω–Ω—ã—Ö —Ä—É—Å—Å–∫–æ-–∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤
        mixed_pattern = r'([–∞-—è–ê-–Ø—ë–Å]+)([a-zA-Z]+)|([a-zA-Z]+)([–∞-—è–ê-–Ø—ë–Å]+)'
        if re.search(mixed_pattern, text):
            # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Å–º–µ—à–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞, –ø—ã—Ç–∞–µ–º—Å—è –∏—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç—å
            text = re.sub(r'([–∞-—è–ê-–Ø—ë–Å])([a-zA-Z])', r'\1 \2', text)
            text = re.sub(r'([a-zA-Z])([–∞-—è–ê-–Ø—ë–Å])', r'\1 \2', text)
            
            # –£–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ –≤ –∫–æ–Ω—Ü–µ
            text = re.sub(r'\s+[a-zA-Z]+\s*$', '', text.strip())
            
            # –£–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞—á–∞–ª–µ
            text = re.sub(r'^[a-zA-Z]+\s+', '', text.strip())
        
        # –£–õ–£–ß–®–ï–ù–ò–ï: –£–±–∏—Ä–∞–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –æ—Å—Ç–∞–ª–∏—Å—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞
        english_words = re.findall(r'\b[a-zA-Z]{2,}\b', text)
        if english_words:
            # –£–±–∏—Ä–∞–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            for word in english_words:
                text = re.sub(r'\b' + re.escape(word) + r'\b', '', text)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'\s+', ' ', text).strip()
        text = re.sub(r'\s*,\s*,+', ',', text)  # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—è—Ç—ã–µ
        text = re.sub(r'\s*\.\s*\.+', '.', text)  # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏
        
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –ø—É—Å—Ç–∞—è –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
        if not text:
            return text
        
        # –ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–∞—Ä–∫–µ—Ä –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentence_endings = ['.', '!', '?', '‚Ä¶']
        last_end_index = max((text.rfind(sep) for sep in sentence_endings))

        if last_end_index != -1:
            finalized = text[: last_end_index + 1].strip()
        else:
            # –ï—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–µ—Ç –æ–∫–æ–Ω—á–∞–Ω–∏—è, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–π —Ç–æ—á–∫–æ–π
            finalized = text.rstrip()
            if not finalized.endswith('.'):
                finalized += '.'

        # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –ø—Ä–∞–≤–∫–∞ –≤–∏—Å—è—â–∏—Ö –∫–∞–≤—ã—á–µ–∫/—Å–∫–æ–±–æ–∫ –≤ –∫–æ–Ω—Ü–µ
        dangling = ['"', "'", '¬´', '"', '"', '‚Äû', '(', '[', '{']
        while finalized and finalized[-1] in dangling:
            finalized = finalized[:-1].rstrip()

        return finalized

    async def generate_response(self, messages: list, user_message: str = "") -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç"""
        if not self.is_loaded:
            return "‚ùå AI –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
            
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è chat-completions —Å —É—á–µ—Ç–æ–º –≤–∞—à–µ–π –∏—Å—Ç–æ—Ä–∏–∏
            chat_messages = []
            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º –ø–æ –ú–°–ö
            system_prompt_text = get_system_prompt()
            if system_prompt_text:
                chat_messages.append({"role": "system", "content": system_prompt_text})
            if messages:
                for msg in messages:  # –æ–≥—Ä–∞–Ω–∏—á–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    text = msg.get("text", "").strip()
                    if not text:
                        continue
                    role = "assistant" if msg.get("is_outgoing", False) else "user"
                    chat_messages.append({"role": role, "content": text})

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑ AI_SETTINGS
            temperature = AI_SETTINGS.get('temperature', 0.7)
            top_p = AI_SETTINGS.get('top_p', 0.95)
            max_new_tokens = AI_SETTINGS.get('max_new_tokens', 200)
            repetition_penalty = AI_SETTINGS.get('repetition_penalty', 1.3)

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ chat API (Llama 3 RP)
            response = self.model.create_chat_completion(
                messages=chat_messages,
                temperature=temperature,
                top_p=top_p,
                top_k=30,
                typical_p=0.98,
                min_p=0.05,
                max_tokens=max_new_tokens,
                repeat_penalty=repetition_penalty,
                stop=[
                    "User:", "Assistant:", "–ö—Å—é—à–∞:", "\nUser", "\nAssistant",
                    "—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å", "–Ø —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å", "LMSYS", "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π",
                    "language model", "–Ø –º–æ–¥–µ–ª—å", "—è –º–æ–¥–µ–ª—å", "–Ω–µ–π—Ä–æ—Å–µ—Ç—å",
                ]
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            if response and 'choices' in response and len(response['choices']) > 0:
                choice = response['choices'][0]
                # llama.cpp chat-completions –ø–æ–º–µ—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ message.content
                result = (choice.get('message', {}) or {}).get('content', '') or choice.get('text', '')
                result = (result or '').strip()
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                result = self._translate_to_russian(result)
                # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ/–æ–±—Ä–µ–∑–∞–µ–º –¥–æ –ø–æ–ª–Ω–æ–≥–æ
                result = self._finalize_response(result)
                return result if result else None
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return None

